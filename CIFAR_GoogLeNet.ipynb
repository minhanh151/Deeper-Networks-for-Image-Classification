{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXt05UtlLUcz"
      },
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import datasets, layers, models, losses, Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import AveragePooling2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import concatenate\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
        "trainX = trainX.astype(\"float\")\n",
        "testX = testX.astype(\"float\")\n",
        "                                # Step 1\n",
        "mean = np.mean(trainX, axis=0)\n",
        "trainX -= mean\n",
        "testX -= mean\n",
        "                                # Step 2\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)\n",
        "                                # Step 3\n",
        "aug = ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1, horizontal_flip=True,fill_mode=\"nearest\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byk-N3zzv_35",
        "outputId": "442a1647-f214-4563-db4e-698c8fc6c11f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wKcYCdaLcFU"
      },
      "source": [
        "def inception(x,\n",
        "              filters_1x1,\n",
        "              filters_3x3_reduce,\n",
        "              filters_3x3,\n",
        "              filters_5x5_reduce,\n",
        "              filters_5x5,\n",
        "              filters_pool):\n",
        "  path1 = layers.Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "  path2 = layers.Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n",
        "  path2 = layers.Conv2D(filters_3x3, (1, 1), padding='same', activation='relu')(path2)\n",
        "\n",
        "  path3 = layers.Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n",
        "  path3 = layers.Conv2D(filters_5x5, (1, 1), padding='same', activation='relu')(path3)\n",
        "\n",
        "  path4 = layers.MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  path4 = layers.Conv2D(filters_pool, (1, 1), padding='same', activation='relu')(path4)\n",
        "\n",
        "  return tf.concat([path1, path2, path3, path4], axis=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDEI1TMtLcHq"
      },
      "source": [
        "inp = layers.Input(shape=(32, 32, 3))\n",
        "input_tensor = layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=trainX.shape[1:])(inp)\n",
        "\n",
        "x = layers.Conv2D(64, 7, strides=2, padding='same', activation='relu')(input_tensor)\n",
        "x = layers.MaxPooling2D(3, strides=2)(x)\n",
        "\n",
        "x = layers.Conv2D(64, 1, strides=1, padding='same', activation='relu')(x)\n",
        "x = layers.Conv2D(192, 3, strides=1, padding='same', activation='relu')(x)\n",
        "\n",
        "x = layers.MaxPooling2D(3, strides=2)(x)\n",
        "\n",
        "x = inception(x,\n",
        "              filters_1x1=64,\n",
        "              filters_3x3_reduce=96,\n",
        "              filters_3x3=128,\n",
        "              filters_5x5_reduce=16,\n",
        "              filters_5x5=32,\n",
        "              filters_pool=32)\n",
        "\n",
        "x = inception(x,\n",
        "              filters_1x1=128,\n",
        "              filters_3x3_reduce=128,\n",
        "              filters_3x3=192,\n",
        "              filters_5x5_reduce=32,\n",
        "              filters_5x5=96,\n",
        "              filters_pool=64)\n",
        "\n",
        "x = layers.MaxPooling2D(3, strides=2)(x)\n",
        "\n",
        "x = inception(x,\n",
        "              filters_1x1=192,\n",
        "              filters_3x3_reduce=96,\n",
        "              filters_3x3=208,\n",
        "              filters_5x5_reduce=16,\n",
        "              filters_5x5=48,\n",
        "              filters_pool=64)\n",
        "\n",
        "aux1 = layers.AveragePooling2D((5, 5), strides=3)(x)\n",
        "aux1 = layers.Conv2D(128, 1, padding='same', activation='relu')(aux1)\n",
        "aux1 = layers.Flatten()(aux1)\n",
        "aux1 = layers.Dense(1024, activation='relu')(aux1)\n",
        "aux1 = layers.Dropout(0.7)(aux1)\n",
        "aux1 = layers.Dense(10, activation='softmax')(aux1)\n",
        "\n",
        "x = inception(x,\n",
        "              filters_1x1=160,\n",
        "              filters_3x3_reduce=112,\n",
        "              filters_3x3=224,\n",
        "              filters_5x5_reduce=24,\n",
        "              filters_5x5=64,\n",
        "              filters_pool=64)\n",
        "\n",
        "x = inception(x,\n",
        "              filters_1x1=128,\n",
        "              filters_3x3_reduce=128,\n",
        "              filters_3x3=256,\n",
        "              filters_5x5_reduce=24,\n",
        "              filters_5x5=64,\n",
        "              filters_pool=64)\n",
        "\n",
        "x = inception(x,\n",
        "              filters_1x1=112,\n",
        "              filters_3x3_reduce=144,\n",
        "              filters_3x3=288,\n",
        "              filters_5x5_reduce=32,\n",
        "              filters_5x5=64,\n",
        "              filters_pool=64)\n",
        "\n",
        "aux2 = layers.AveragePooling2D((5, 5), strides=3)(x)\n",
        "aux2 = layers.Conv2D(128, 1, padding='same', activation='relu')(aux2)\n",
        "aux2 = layers.Flatten()(aux2)\n",
        "aux2 = layers.Dense(1024, activation='relu')(aux2)\n",
        "aux2 = layers.Dropout(0.7)(aux2)\n",
        "aux2 = layers.Dense(10, activation='softmax')(aux2)\n",
        "\n",
        "x = inception(x,\n",
        "              filters_1x1=256,\n",
        "              filters_3x3_reduce=160,\n",
        "              filters_3x3=320,\n",
        "              filters_5x5_reduce=32,\n",
        "              filters_5x5=128,\n",
        "              filters_pool=128)\n",
        "\n",
        "x = layers.MaxPooling2D(3, strides=2)(x)\n",
        "\n",
        "x = inception(x,\n",
        "              filters_1x1=256,\n",
        "              filters_3x3_reduce=160,\n",
        "              filters_3x3=320,\n",
        "              filters_5x5_reduce=32,\n",
        "              filters_5x5=128,\n",
        "              filters_pool=128)\n",
        "\n",
        "x = inception(x,\n",
        "              filters_1x1=384,\n",
        "              filters_3x3_reduce=192,\n",
        "              filters_3x3=384,\n",
        "              filters_5x5_reduce=48,\n",
        "              filters_5x5=128,\n",
        "              filters_pool=128)\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = layers.Dropout(0.4)(x)\n",
        "out = layers.Dense(10, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 30\n",
        "INIT_LR = 5e-3\n",
        "def poly_decay(epoch):\n",
        "  maxEpochs = NUM_EPOCHS\n",
        "  baseLR = INIT_LR\n",
        "  power = 1.0\n",
        "  alpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
        "  return alpha"
      ],
      "metadata": {
        "id": "0WDV_EOTwM_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks=[LearningRateScheduler(poly_decay)]\n",
        "opt = SGD(learning_rate=INIT_LR, momentum=0.9)\n",
        "\n",
        "model = Model(inputs = inp, outputs = out)\n",
        "                                    # Step 1\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "                                    # Step 2\n",
        "# Record start time\n",
        "start_time = time.time()\n",
        "print('Training started at %s', time.ctime(start_time))\n",
        "\n",
        "history = model.fit(aug.flow(trainX, trainY, batch_size=64),validation_data=(testX, testY), steps_per_epoch=len(trainX) // 64,epochs=NUM_EPOCHS, callbacks=callbacks, verbose=1)\n",
        "\n",
        "# Record end time\n",
        "end_time = time.time()\n",
        "print('Training ended at %s', time.ctime(end_time))\n",
        "\n",
        "# Calculate duration of training\n",
        "duration = end_time - start_time\n",
        "print('Training duration: %i seconds', int(duration))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiB2eJNCwKfU",
        "outputId": "2678dcbc-f278-4dae-e149-d7f67ca2c17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started at %s Tue May  9 13:54:54 2023\n",
            "Epoch 1/30\n",
            "781/781 [==============================] - 149s 172ms/step - loss: 1.9106 - accuracy: 0.2618 - val_loss: 1.7129 - val_accuracy: 0.3494 - lr: 0.0050\n",
            "Epoch 2/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 1.6558 - accuracy: 0.3775 - val_loss: 1.4389 - val_accuracy: 0.4652 - lr: 0.0048\n",
            "Epoch 3/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 1.4810 - accuracy: 0.4604 - val_loss: 1.3662 - val_accuracy: 0.5143 - lr: 0.0047\n",
            "Epoch 4/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 1.3486 - accuracy: 0.5134 - val_loss: 1.3754 - val_accuracy: 0.5145 - lr: 0.0045\n",
            "Epoch 5/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 1.2400 - accuracy: 0.5578 - val_loss: 1.2130 - val_accuracy: 0.5816 - lr: 0.0043\n",
            "Epoch 6/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 1.1484 - accuracy: 0.5921 - val_loss: 1.2052 - val_accuracy: 0.5848 - lr: 0.0042\n",
            "Epoch 7/30\n",
            "781/781 [==============================] - 133s 171ms/step - loss: 1.0688 - accuracy: 0.6208 - val_loss: 1.0513 - val_accuracy: 0.6413 - lr: 0.0040\n",
            "Epoch 8/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 1.0011 - accuracy: 0.6459 - val_loss: 0.9640 - val_accuracy: 0.6647 - lr: 0.0038\n",
            "Epoch 9/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.9519 - accuracy: 0.6652 - val_loss: 0.8612 - val_accuracy: 0.7025 - lr: 0.0037\n",
            "Epoch 10/30\n",
            "781/781 [==============================] - 132s 169ms/step - loss: 0.8957 - accuracy: 0.6852 - val_loss: 0.8971 - val_accuracy: 0.6879 - lr: 0.0035\n",
            "Epoch 11/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.8617 - accuracy: 0.6946 - val_loss: 0.9441 - val_accuracy: 0.6919 - lr: 0.0033\n",
            "Epoch 12/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.8173 - accuracy: 0.7142 - val_loss: 0.7647 - val_accuracy: 0.7363 - lr: 0.0032\n",
            "Epoch 13/30\n",
            "781/781 [==============================] - 132s 170ms/step - loss: 0.7824 - accuracy: 0.7262 - val_loss: 0.8098 - val_accuracy: 0.7308 - lr: 0.0030\n",
            "Epoch 14/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.7545 - accuracy: 0.7358 - val_loss: 0.8234 - val_accuracy: 0.7146 - lr: 0.0028\n",
            "Epoch 15/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.7192 - accuracy: 0.7472 - val_loss: 0.7103 - val_accuracy: 0.7569 - lr: 0.0027\n",
            "Epoch 16/30\n",
            "781/781 [==============================] - 132s 169ms/step - loss: 0.6937 - accuracy: 0.7572 - val_loss: 0.8837 - val_accuracy: 0.7188 - lr: 0.0025\n",
            "Epoch 17/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.6671 - accuracy: 0.7693 - val_loss: 0.7547 - val_accuracy: 0.7470 - lr: 0.0023\n",
            "Epoch 18/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.6355 - accuracy: 0.7755 - val_loss: 0.7264 - val_accuracy: 0.7669 - lr: 0.0022\n",
            "Epoch 19/30\n",
            "781/781 [==============================] - 131s 167ms/step - loss: 0.6161 - accuracy: 0.7840 - val_loss: 0.8050 - val_accuracy: 0.7456 - lr: 0.0020\n",
            "Epoch 20/30\n",
            "781/781 [==============================] - 132s 169ms/step - loss: 0.5862 - accuracy: 0.7946 - val_loss: 0.7362 - val_accuracy: 0.7589 - lr: 0.0018\n",
            "Epoch 21/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.5641 - accuracy: 0.7999 - val_loss: 0.6779 - val_accuracy: 0.7726 - lr: 0.0017\n",
            "Epoch 22/30\n",
            "781/781 [==============================] - 130s 167ms/step - loss: 0.5393 - accuracy: 0.8104 - val_loss: 0.6632 - val_accuracy: 0.7797 - lr: 0.0015\n",
            "Epoch 23/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.5150 - accuracy: 0.8212 - val_loss: 0.6545 - val_accuracy: 0.7864 - lr: 0.0013\n",
            "Epoch 24/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.4927 - accuracy: 0.8285 - val_loss: 0.6319 - val_accuracy: 0.7895 - lr: 0.0012\n",
            "Epoch 25/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.4710 - accuracy: 0.8344 - val_loss: 0.6162 - val_accuracy: 0.8049 - lr: 0.0010\n",
            "Epoch 26/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.4491 - accuracy: 0.8433 - val_loss: 0.6124 - val_accuracy: 0.8069 - lr: 8.3333e-04\n",
            "Epoch 27/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.4270 - accuracy: 0.8490 - val_loss: 0.6644 - val_accuracy: 0.7911 - lr: 6.6667e-04\n",
            "Epoch 28/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.4109 - accuracy: 0.8543 - val_loss: 0.6176 - val_accuracy: 0.8104 - lr: 5.0000e-04\n",
            "Epoch 29/30\n",
            "781/781 [==============================] - 133s 170ms/step - loss: 0.3834 - accuracy: 0.8635 - val_loss: 0.6175 - val_accuracy: 0.8087 - lr: 3.3333e-04\n",
            "Epoch 30/30\n",
            "781/781 [==============================] - 131s 167ms/step - loss: 0.3646 - accuracy: 0.8716 - val_loss: 0.6305 - val_accuracy: 0.8115 - lr: 1.6667e-04\n",
            "Training ended at %s Tue May  9 15:04:24 2023\n",
            "Training duration: %i seconds 4170\n"
          ]
        }
      ]
    }
  ]
}